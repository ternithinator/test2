{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genomics_Workshop_part_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ternithinator/test2/blob/main/Genomics_Workshop_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "<video src=\"https://raw.githubusercontent.com/PoODL-CES/PoODL_NGS_workshop.io/main/Nature%20of%20Science.mp4\" controls autoplay loop width=\"400\" align=\"right\"></video>\n",
        "\n",
        "## Genomics Learning Workshop: NGS Analysis Pipeline\n",
        "\n",
        "Easy-to-follow workflow for processing Illumina whole-genome resequencing reads for population genomics. Steps include trimming, mapping, sorting, variant calling, variant filtering, PCA, and ADMIXTURE analysis. For more details, see the bottom of this notebook and visit the GitHub repository.\n",
        "Repository link: [Genomics Learning Workshop](https://github.com/PoODL-CES/Genomics_learning_workshop)\n",
        "\n",
        "This workshop introduces:\n",
        "- Handling raw FASTQ files\n",
        "- Performing quality control and trimming\n",
        "- Mapping reads to a reference genome\n",
        "- Calling and filtering variants\n",
        "- Running PCA and ADMIXTURE for population analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6704e35"
      },
      "source": [
        "# Miniconda installation and environment setup for Colab NGS Workshop\n",
        "\n",
        "# Download and install Miniconda (skip if already installed)\n",
        "!wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "!bash miniconda.sh -b -p /usr/local/miniconda\n",
        "\n",
        "import sys, os\n",
        "sys.path.append('/usr/local/miniconda/lib/python3.8/site-packages')\n",
        "os.environ['PATH'] = \"/usr/local/miniconda/bin:\" + os.environ['PATH']\n",
        "\n",
        "# Explicitly clear potentially problematic environment variables from Python's os.environ\n",
        "if 'CONDA_PREFIX' in os.environ:\n",
        "    del os.environ['CONDA_PREFIX']\n",
        "if 'CONDA_ENVS_PATH' in os.environ:\n",
        "    del os.environ['CONDA_ENVS_PATH']\n",
        "\n",
        "# Accept ToS for main and R conda channels\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
        "\n",
        "# Create new conda environment for your workshop if it doesn't exist\n",
        "!if ! conda info --envs | grep -w 'workshop_ngs'; then \\\n",
        "    conda create -y -n workshop_ngs python=3.7; \\\n",
        "else \\\n",
        "    echo \"Environment 'workshop_ngs' already exists, skipping creation.\"; \\\n",
        "fi\n",
        "\n",
        "# Install necessary bioinformatics tools into the environment\n",
        "!conda install -y -n workshop_ngs -c bioconda -c conda-forge trim-galore samtools fastqc bwa gatk4=4.3.0.0\n",
        "\n",
        "# Verify tool versions inside activated environment in one shell session\n",
        "!bash -c \"source /usr/local/miniconda/bin/activate workshop_ngs && \\\n",
        "          trim_galore --version && samtools --version && fastqc --version && \\\n",
        "          bwa --version && gatk --version\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70edf711"
      },
      "source": [
        "To activate the `workshop_ngs` environment for specific commands and ensure its tools are used, you can wrap your commands within a `bash -c \"source /usr/local/miniconda/bin/activate workshop_ngs && your_command_here\"` block. This ensures the environment is properly sourced before the command runs. Let's try listing the environment contents and checking `CONDA_PREFIX` within that activated session:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2f52e3b"
      },
      "source": [
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && conda activate workshop_ngs && \\\n",
        "          echo '--- Environment activated ---' && \\\n",
        "          echo 'CONDA_PREFIX in activated env: '$CONDA_PREFIX && \\\n",
        "          echo '--- Listing contents of activated env ---' && \\\n",
        "          conda list\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c5c06e3"
      },
      "source": [
        "We’ll be using real WGS resequencing data for this workshop. The dataset is a small subset for demonstration purposes. We will download the data from (https://zenodo.org/records/14258052) . Step 1 would be to make a parent directory to sort all the data in one place.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0a0fc21"
      },
      "source": [
        "%%bash\n",
        "\n",
        "mkdir -p fastq_files\n",
        "ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58d954b7"
      },
      "source": [
        "Now, let's navigate into the `fastq_files` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd7e272d"
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd fastq_files/ && pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6ca911"
      },
      "source": [
        "Let's organize the download process by first ensuring the `fastq_files` directory exists, then navigating into it to download all the FASTQ files directly to their intended location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6bbeb7"
      },
      "source": [
        "# Define the list of FASTQ file links\n",
        "fastq_links = [\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_CI16_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_CI16_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW10_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_NW10_sub_2.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI18_sub_1.fq.gz\",\n",
        "    \"https://zenodo.org/records/14258052/files/BEN_SI18_sub_2.fq.gz\",\n",
        "]\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "!mkdir -p fastq_files\n",
        "\n",
        "# Clean up any existing fastq files and duplicates before downloading\n",
        "!rm -f fastq_files/*.fq.gz*\n",
        "\n",
        "# Change to the directory and download files\n",
        "for link in fastq_links:\n",
        "    # Use -nc (no-clobber) to avoid re-downloading if file exists and is complete,\n",
        "    # and -P . to save to current directory (fastq_files after cd)\n",
        "    !bash -c \"cd fastq_files && wget -nc -P . -q {link}\"\n",
        "\n",
        "# List the contents of the fastq_files directory to confirm all downloads\n",
        "!ls -F fastq_files/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualise the content of the directory 'fastq_files' , to confirm that all the files have been successfully downloaded."
      ],
      "metadata": {
        "id": "NIKJbD1kB49q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e74bb29"
      },
      "source": [
        "Once all the fastq files are downloaded, the next would be to run \"FastQC\" tool on the raw reads for the quality assessment step before the downstream analysis part.\n",
        "\n",
        "***Why it's important:*** Poor-quality reads can lead to false variant calls or poor mapping, so quality control is crucial.\n",
        "\n",
        "To do so, first, let's create a directory to store the FastQC reports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93be3c96"
      },
      "source": [
        "%%bash\n",
        "\n",
        "mkdir -p fastqc_results\n",
        "ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cf4153e"
      },
      "source": [
        "Now, we will run FastQC on all the FASTQ files within the `workshop_ngs` environment and save the reports to the `fastqc_results` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddc193b1"
      },
      "source": [
        "%%time\n",
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && conda activate workshop_ngs && \\\n",
        "          fastqc fastq_files/*.fq.gz -o fastqc_results\"\n",
        "\n",
        "# List the generated FastQC reports\n",
        "!ls -F fastqc_results/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The .html files generated by FastQC are standard web pages, which means you can visualize them by opening them in any web browser!\n",
        "\n",
        "Here's how you can access them from Colab:\n",
        " On the left-hand side of your Colab interface, there's usually a file explorer icon (a folder). Click on it to open the file browser. Navigate to the fastqc_results directory. You'll see all the .html files listed there. You can right-click on any .html file and select 'Download' to save it to your local machine, then open it with your preferred web browser.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TLmb_MoTEJ-p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26726bab"
      },
      "source": [
        "Post qualitty assessment, the next step will be the trimming of the adapters or low-quality bases using tools such as Trim-galore. This step will ensure producing clean FASTQ files, ready for mapping.\n",
        "\n",
        "Step 1: We'll create a directory to store the trimmed FASTQ files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06e02af7"
      },
      "source": [
        "!mkdir -p trimmed_fastq_files\n",
        "!ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bbe2bd9"
      },
      "source": [
        "Now, we will activate the `workshop_ngs` conda environment and run `Trim Galore!` on all the FASTQ files. We'll specify that they are paired-end reads and direct the output to the `trimmed_fastq_files` directory.\n",
        "\n",
        "Trim Galore automatically detects and removes common adapter sequences and performs quality trimming. The `--paired` option is essential for correctly processing paired-end reads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3bd792c"
      },
      "source": [
        "%%time\n",
        "# Run Trim Galore! within the activated conda environment\n",
        "# We iterate through the samples to process paired-end reads correctly\n",
        "\n",
        "import os\n",
        "\n",
        "# Get a list of fastq files programmatically\n",
        "all_files = os.listdir('fastq_files/')\n",
        "fastq_files_list = [os.path.join('fastq_files', f) for f in all_files if f.endswith('.fq.gz')]\n",
        "\n",
        "# Extract unique sample prefixes (e.g., BEN_CI16, BEN_NW10, BEN_SI18) from the filenames\n",
        "sample_prefixes = sorted(list(set([f.split('/')[-1].split('_sub_')[0] for f in fastq_files_list])))\n",
        "\n",
        "print(f\"Detected FASTQ files: {fastq_files_list}\")\n",
        "print(f\"Detected sample prefixes: {sample_prefixes}\")\n",
        "\n",
        "for prefix in sample_prefixes:\n",
        "    read1 = f\"fastq_files/{prefix}_sub_1.fq.gz\"\n",
        "    read2 = f\"fastq_files/{prefix}_sub_2.fq.gz\"\n",
        "    output_dir = \"trimmed_fastq_files\"\n",
        "\n",
        "    # Use bash -c to activate conda env and run trim_galore\n",
        "    # --paired: for paired-end reads\n",
        "    # -o: specify output directory\n",
        "    # --fastqc is removed as per user request to avoid generating html/zip files\n",
        "    !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && conda activate workshop_ngs && \\\n",
        "              trim_galore --paired {read1} {read2} -o {output_dir}\"\n",
        "\n",
        "    # Remove unwanted output files for the current prefix\n",
        "    !rm -f {output_dir}/{prefix}_sub_*.fq.gz_trimming_report.txt\n",
        "    !rm -f {output_dir}/{prefix}_sub_*_fastqc.html\n",
        "    !rm -f {output_dir}/{prefix}_sub_*_fastqc.zip\n",
        "\n",
        "# List the contents of the trimmed_fastq_files directory to confirm only _val files remain\n",
        "!ls -F trimmed_fastq_files/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "\n",
        "# Direct paths for this single sample\n",
        "read1 = \"fastq_files/BEN_CI16_sub_1.fq.gz\"\n",
        "read2 = \"fastq_files/BEN_CI16_sub_2.fq.gz\"\n",
        "output_dir = \"trimmed_fastq_files\"\n",
        "\n",
        "# Make output directory if missing\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"\\n--- Running Trim Galore for BEN_CI16 ---\")\n",
        "\n",
        "# Run Trim Galore inside conda environment\n",
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "          conda activate workshop_ngs && \\\n",
        "          trim_galore --paired {read1} {read2} -o {output_dir}\"\n",
        "\n",
        "# Remove unwanted reports and QC files\n",
        "!rm -f {output_dir}/BEN_CI16_sub_*.fq.gz_trimming_report.txt\n",
        "!rm -f {output_dir}/BEN_CI16_sub_*_fastqc.html\n",
        "!rm -f {output_dir}/BEN_CI16_sub_*_fastqc.zip\n",
        "\n",
        "# Show trimmed output files\n",
        "print('\\n--- Trimmed files in trimmed_fastq_files/ ---')\n",
        "!ls -F trimmed_fastq_files/\n"
      ],
      "metadata": {
        "id": "uBB4jsmR6Xu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ead2635"
      },
      "source": [
        "### Downloading reference files for mapping\n",
        "\n",
        "To prepare for the read mapping step, we need to download the reference genome and its associated index files. These files will be stored in a new directory called `reference`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!rm -rf reference\n",
        "reference_tar = \"https://zenodo.org/records/17878528/files/reference.tar.gz?download=1\"\n",
        "\n",
        "# Download the tar.gz file\n",
        "!wget -q $reference_tar -O reference.tar.gz\n",
        "\n",
        "# Extract it — this will unpack into its own folder (likely 'reference/')\n",
        "!tar -xzvf reference.tar.gz\n",
        "\n",
        "# List extracted contents\n",
        "!ls -F reference/"
      ],
      "metadata": {
        "id": "0qiw_azslQFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea38b6a9"
      },
      "source": [
        "# Mapping reads to the Reference genome:\n",
        "Here we:\n",
        "\n",
        "Use an aligner like BWA or Bowtie2 to map the cleaned reads to a reference genome\n",
        "\n",
        "Convert output from SAM to BAM format (compressed and binary)\n",
        "\n",
        "Sort the BAM files by genomic coordinates (using samtools sort)\n",
        "\n",
        "\n",
        "Index the BAM files so tools can access them efficiently\n",
        "\n",
        "*Why it's important:* Proper alignment is the foundation for all downstream analysis. Sorting/indexing ensures quick and efficient variant detection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new directory named `mapped_reads` to store output alignment files, then index the reference genome located at `reference/GCA_021130815.1_PanTigT.MC.v3_genomic.fna` using `bwa index` for efficient read mapping. After indexing, map the trimmed paired-end reads from each sample to the indexed reference genome using `bwa mem`, converting the output to sorted BAM files and indexing them using `samtools`."
      ],
      "metadata": {
        "id": "rlOQNcpAF1ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p mapped_reads\n",
        "\n",
        "# Paths for this sample\n",
        "REFERENCE_GENOME = \"reference/GCA_021130815.1_PanTigT.MC.v3_genomic.fna\"\n",
        "\n",
        "read1 = \"trimmed_fastq_files/BEN_CI16_sub_1_val_1.fq.gz\"\n",
        "read2 = \"trimmed_fastq_files/BEN_CI16_sub_2_val_2.fq.gz\"\n",
        "output_bam = \"mapped_reads/BEN_CI16.bam\"\n",
        "\n",
        "print(\"\\n--- Mapping BEN_CI16 ---\")\n",
        "\n",
        "# Map + convert to BAM + sort BAM\n",
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "          conda activate workshop_ngs && \\\n",
        "          bwa mem -M -R '@RG\\tID:BEN_CI16\\tSM:BEN_CI16\\tPL:ILLUMINA' \\\n",
        "          {REFERENCE_GENOME} {read1} {read2} | \\\n",
        "          samtools view -bS - | \\\n",
        "          samtools sort -o {output_bam} -\"\n",
        "\n",
        "# Index sorted BAM\n",
        "#print(\"Indexing BEN_CI16...\")\n",
        "#!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        " #         conda activate workshop_ngs && \\\n",
        "  #        samtools index {output_bam}\"\n",
        "\n",
        "# List output files\n",
        "!ls -lh mapped_reads/\n"
      ],
      "metadata": {
        "id": "J56P3nBKnGm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mark Duplicates\n",
        "\n",
        "This command detects PCR duplicates and optical duplicates in the aligned reads and removes them. Duplicate reads can bias downstream analyses such as variant calling, so removing them improves data quality.\n",
        "\n",
        "Explanation of the flags we use are given below\n",
        "\n",
        "-I : Input BAM file. This is the sorted BAM produced from the mapping step.\n",
        "\n",
        "-O :\tOutput BAM file after duplicates have been removed.\n",
        "\n",
        "-M :\tFile where GATK writes duplication statistics (number of duplicates, percent duplication, etc.)\n",
        "\n",
        "--REMOVE_DUPLICATES true :\tInstead of just marking duplicates, this flag instructs GATK to remove them entirely from the BAM file.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**After mark duplicates we also need to Index the deduplicated bam file**\n",
        "\n",
        "Creates an index (.bai) file for the deduplicated BAM file.\n",
        "This index enables efficient random access to the BAM file and is required for many downstream tools\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y-jVE9177vj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "          conda activate workshop_ngs && \\\n",
        "          gatk MarkDuplicates \\\n",
        "            -I BEN_CI16.bam \\\n",
        "            -O BEN_CI16.deduplicated.bam \\\n",
        "            -M BEN_CI16.metrics.txt \\\n",
        "            --REMOVE_DUPLICATES true\"\n",
        "\n",
        "\n",
        "print(\"\\n--- Indexing deduplicated BAM ---\")\n",
        "\n",
        "!bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "          conda activate workshop_ngs && \\\n",
        "          samtools index mapped_reads/BEN_CI16.deduplicated.bam\"\n",
        "\n",
        "# List output files\n",
        "!ls -lh mapped_reads/"
      ],
      "metadata": {
        "id": "MtmP9ayY7x-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tutorial Exercise\n",
        "\n",
        "Once you have performed trimming and mapping and completed till indexing steps given above, same can be done for the other two fastq files which we have downloaded (BEN_NW10 and BEN_SI18).\n",
        "\n",
        "Steps for the same are given below."
      ],
      "metadata": {
        "id": "sOiWTqu5o5n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trimming**"
      ],
      "metadata": {
        "id": "Ik1RVN1Wqt9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "\n",
        "samples = [\"BEN_NW10\", \"BEN_SI18\"]\n",
        "output_dir = \"trimmed_fastq_files\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for prefix in samples:\n",
        "    read1 = f\"fastq_files/{prefix}_sub_1.fq.gz\"\n",
        "    read2 = f\"fastq_files/{prefix}_sub_2.fq.gz\"\n",
        "\n",
        "    print(f\"\\n--- Running Trim Galore for {prefix} ---\")\n",
        "\n",
        "    # Run Trim Galore inside conda environment\n",
        "    !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "              conda activate workshop_ngs && \\\n",
        "              trim_galore --paired {read1} {read2} -o {output_dir}\"\n",
        "\n",
        "    # Remove extra report files\n",
        "    !rm -f {output_dir}/{prefix}_sub_*.fq.gz_trimming_report.txt\n",
        "    !rm -f {output_dir}/{prefix}_sub_*_fastqc.html\n",
        "    !rm -f {output_dir}/{prefix}_sub_*_fastqc.zip\n",
        "\n",
        "print(\"\\n--- Trimmed files ---\")\n",
        "!ls -F trimmed_fastq_files/\n"
      ],
      "metadata": {
        "id": "IUr6WXTh7zVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mapping**"
      ],
      "metadata": {
        "id": "gwOLBLtAqwWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "REFERENCE_GENOME = \"reference/GCA_021130815.1_PanTigT.MC.v3_genomic.fna\"\n",
        "os.makedirs(\"mapped_reads\", exist_ok=True)\n",
        "\n",
        "samples = [\"BEN_NW10\", \"BEN_SI18\"]\n",
        "\n",
        "for prefix in samples:\n",
        "\n",
        "    read1 = f\"trimmed_fastq_files/{prefix}_sub_1_val_1.fq.gz\"\n",
        "    read2 = f\"trimmed_fastq_files/{prefix}_sub_2_val_2.fq.gz\"\n",
        "    output_bam = f\"mapped_reads/{prefix}.bam\"\n",
        "\n",
        "    print(f\"\\n--- Mapping {prefix} ---\")\n",
        "\n",
        "    # Map → convert → sort\n",
        "    !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "              conda activate workshop_ngs && \\\n",
        "              bwa mem -M -R '@RG\\tID:{prefix}\\tSM:{prefix}\\tPL:ILLUMINA' \\\n",
        "              {REFERENCE_GENOME} {read1} {read2} | \\\n",
        "              samtools view -bS - | \\\n",
        "              samtools sort -o {output_bam} -\"\n",
        "\n",
        "    # Index BAM\n",
        "   # print(f\"Indexing BAM for {prefix}...\")\n",
        "  #  !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "        #      conda activate workshop_ngs && \\\n",
        "      #        samtools index {output_bam}\"\n",
        "\n",
        "\n",
        "!ls -F mapped_reads/\n"
      ],
      "metadata": {
        "id": "nUI-4nLp71fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mark Duplicates + Indexing**"
      ],
      "metadata": {
        "id": "INA7a0DhqyV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\"BEN_NW10\", \"BEN_SI18\"]\n",
        "\n",
        "for prefix in samples:\n",
        "    print(f\"\\n--- Running MarkDuplicates for {prefix} ---\")\n",
        "\n",
        "    !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "              conda activate workshop_ngs && \\\n",
        "              gatk MarkDuplicates \\\n",
        "                -I mapped_reads/{prefix}.sorted.bam \\\n",
        "                -O mapped_reads/{prefix}.deduplicated.bam \\\n",
        "                -M mapped_reads/{prefix}.metrics.txt \\\n",
        "                --REMOVE_DUPLICATES true\"\n",
        "\n",
        "    print(f\"\\n--- Indexing deduplicated BAM for {prefix} ---\")\n",
        "\n",
        "    !bash -c \"source /usr/local/miniconda/etc/profile.d/conda.sh && \\\n",
        "              conda activate workshop_ngs && \\\n",
        "              samtools index mapped_reads/{prefix}.deduplicated.bam\"\n",
        "\n",
        "print(\"\\n--- Finished MarkDuplicates + Indexing for all samples ---\")\n",
        "!ls -lh mapped_reads/\n"
      ],
      "metadata": {
        "id": "XXNUpi7Cqb5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}